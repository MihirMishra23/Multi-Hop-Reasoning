import json
import logging
from argparse import ArgumentParser
from pathlib import Path

import pandas as pd
# from phantom_eval.evaluate_utils import _get_preds

# from memento.utils import get_parser

logger = logging.getLogger(__name__)


def get_hotpot_data_path(data_path: str, split: str, setting: str) -> str:
    """Get the path to the HotpotQA dataset."""
    if split in ["train", "minitrain"]:
        return Path(data_path) / f"hotpot_{split}_v1.1.json"
    else:
        return Path(data_path) / f"hotpot_{split}_{setting}_v1.json"


def load_data(data_path: str, split: str, setting: str) -> dict:
    """Load HotpotQA dataset from disk.

    Args:
        data_path: Path to the dataset directory
        split: Dataset split (e.g., 'hotpot_dev_distractor_v1')
        setting: Either distractor or fullwiki

    Returns:
        dict: Dictionary containing:
            - qa_pairs: List of QA pairs with metadata
            - text: List of context paragraphs with metadata
    """
    file_path = get_hotpot_data_path(data_path, split, setting)
    logger.info(f"Loading HotpotQA dataset from {file_path}")

    with open(file_path) as f:
        data = json.load(f)

    # Convert to format similar to phantom-wiki
    qa_pairs = []
    text_corpus = []

    articles = {}
    for group in data:
        # Process articles
        titles, text = [], []
        for title, article in group["context"]:
            if title in articles:
                if articles[title] != article:
                    logger.warning(f"Article with {title=} already exists with different content")
            else:
                articles[title] = article
            titles.append(title)
            text.append("\n".join(article))
        text_corpus.append(
            {
                "title": titles,
                # NOTE: article is a list of sentences , which we convert to a single string
                "article": text,
                "id": group["_id"],
            }
        )

        qa_pairs.append(
            {
                "id": group["_id"],
                "question": group["question"],
                "answer": group["answer"],
                "type": group["type"],
            }
        )

    # Log final statistics
    logger.info(f"Loaded {len(qa_pairs)} questions " f"and {len(text_corpus)} articles")

    return {
        "qa_pairs": qa_pairs,
        "text": text_corpus,
    }


def load_hotpot_preds(output_dir: str, method: str) -> dict:
    """Loads predictions saved in the format of PhantomEval
    and converts it to the format expected by the HotpotQA evaluation script.

    Args:
        output_dir: Path to the output directory
        method: Method name to filter predictions by
    Returns:
        dict: Dictionary containing:
            - qa_pairs: List of QA pairs with predictions
            - text: List of context paragraphs with predictions
    """

    df_preds = _get_preds(output_dir, method)
    preds = {}
    for row in df_preds.itertuples():
        qid = row.id
        pred = row.pred
        preds[qid] = pred
    return preds


def get_plans_with_qa(
    output_dir: str,
    method: str,
    data_dir: str,
    split: str,
    setting: str,
):
    """
    Read the generated plans for the HotpotQA dataset from the output directory.
    For plans generated by oracle or CoTPlanningAgent
    Args:
        output_dir (str): Path to the output directory
        method (str): Method used for inference (e.g., "cot_plan")
        data_dir (str): Path to the data directory
        split (str): train, dev, test, minidev
        setting (str): distractor, fullwiki

    Returns:
        pd.DataFrame: DataFrame containing the plans with the QA pairs
        Columns are :
        ['id', 'true', 'pred', 'error', 'interaction', 'inference_params',
       'model_kwargs', 'agent_kwargs', 'usage', '_model', '_split',
       '_batch_size', '_batch_number', 'type', '_seed', 'question', 'text_corpus']

    """
    # Get the predictions and filter by split
    df_preds = _get_preds(output_dir, method)
    if df_preds.empty:
        return df_preds
    df_preds = df_preds[df_preds["_split"] == split]

    # Get the QA pairs
    dataset = load_data(data_dir, split, setting)

    df_qa_pairs = pd.DataFrame(dataset["qa_pairs"])
    df_text = pd.DataFrame(dataset["text"])
    # join on the questions for planning with oracle information
    df_preds = df_preds.merge(df_qa_pairs, on="id", how="left", suffixes=("", "_qa"))
    # join on the text corpus for execution
    df_preds = df_preds.merge(df_text, on="id", how="left", suffixes=("", "_text"))

    assert len(dataset["qa_pairs"]) == df_preds.shape[0], (
        f"Obtained {df_preds.shape[0]} plans for split='{split}'"
        f" but expected {len(dataset['qa_pairs'])}"
        "Please run the plan.py script with the same split."
    )
    return df_preds


def get_hotpot_parser() -> ArgumentParser:
    parser = ArgumentParser(parents=[get_parser()], conflict_handler="resolve")
    parser.add_argument(
        "--setting",
        "-s",
        type=str,
        default="distractor",
        help="Either distractor or fullwiki",
    )
    return parser
